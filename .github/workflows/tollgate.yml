name: CI tollgate

on:
  pull_request:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  run-backend-tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: "17"
          distribution: "temurin"
          cache: maven

      - name: Run unit tests
        working-directory: ./backend
        continue-on-error: true
        run: |
          ./mvnw test -Dtest=*Test,*Tests -DexcludeGroups=integration

      - name: Generate JUnit report summary
        if: always()
        working-directory: ./backend
        run: |
          if [ -d "target/surefire-reports" ]; then
            # Count test results
            TOTAL=$(find target/surefire-reports -name "TEST-*.xml" -exec grep -h 'tests=' {} \; | sed 's/.*tests="\([0-9]*\)".*/\1/' | awk '{s+=$1} END {print s}')
            FAILURES=$(find target/surefire-reports -name "TEST-*.xml" -exec grep -h 'failures=' {} \; | sed 's/.*failures="\([0-9]*\)".*/\1/' | awk '{s+=$1} END {print s}')
            ERRORS=$(find target/surefire-reports -name "TEST-*.xml" -exec grep -h 'errors=' {} \; | sed 's/.*errors="\([0-9]*\)".*/\1/' | awk '{s+=$1} END {print s}')
            SKIPPED=$(find target/surefire-reports -name "TEST-*.xml" -exec grep -h 'skipped=' {} \; | sed 's/.*skipped="\([0-9]*\)".*/\1/' | awk '{s+=$1} END {print s}')
            
            # Set defaults if empty
            TOTAL=${TOTAL:-0}
            FAILURES=${FAILURES:-0}
            ERRORS=${ERRORS:-0}
            SKIPPED=${SKIPPED:-0}
            
            PASSED=$((TOTAL - FAILURES - ERRORS - SKIPPED))
            
            echo "TOTAL_TESTS=$TOTAL" >> $GITHUB_ENV
            echo "PASSED_TESTS=$PASSED" >> $GITHUB_ENV
            echo "FAILED_TESTS=$FAILURES" >> $GITHUB_ENV
            echo "ERROR_TESTS=$ERRORS" >> $GITHUB_ENV
            echo "SKIPPED_TESTS=$SKIPPED" >> $GITHUB_ENV
          else
            echo "TOTAL_TESTS=0" >> $GITHUB_ENV
            echo "PASSED_TESTS=0" >> $GITHUB_ENV
            echo "FAILED_TESTS=0" >> $GITHUB_ENV
            echo "ERROR_TESTS=0" >> $GITHUB_ENV
            echo "SKIPPED_TESTS=0" >> $GITHUB_ENV
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: backend/target/surefire-reports/

  merge-check:
    runs-on: ubuntu-latest
    needs: [run-backend-tests]
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check if branch can be merged
        run: |
          git fetch origin main 2>/dev/null || git fetch origin master 2>/dev/null
          git merge --no-commit --no-ff origin/main 2>/dev/null || git merge --no-commit --no-ff origin/master 2>/dev/null || {
            echo "Merge conflicts detected. Please resolve them before merging.";
            exit 1;
          }

  comment-results:
    runs-on: ubuntu-latest
    needs: [run-backend-tests]
    if: always() && github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: test-results

      - name: Comment on PR with results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let testOutput = '';
            let failWorkflow = false;

            // Read test results from XML files
            const testResultsDir = 'test-results';

            if (fs.existsSync(testResultsDir)) {
              const xmlFiles = fs.readdirSync(testResultsDir).filter(f => f.startsWith('TEST-') && f.endsWith('.xml'));
              
              if (xmlFiles.length > 0) {
                let totalTests = 0;
                let passedTests = 0;
                let failedTests = 0;
                let errorTests = 0;
                let skippedTests = 0;
                const testDetails = [];

                // Parse each XML file
                xmlFiles.forEach(file => {
                  const content = fs.readFileSync(path.join(testResultsDir, file), 'utf-8');
                  
                  const testsMatch = content.match(/tests="(\d+)"/);
                  const failuresMatch = content.match(/failures="(\d+)"/);
                  const errorsMatch = content.match(/errors="(\d+)"/);
                  const skippedMatch = content.match(/skipped="(\d+)"/);
                  
                  const tests = testsMatch ? parseInt(testsMatch[1]) : 0;
                  const failures = failuresMatch ? parseInt(failuresMatch[1]) : 0;
                  const errors = errorsMatch ? parseInt(errorsMatch[1]) : 0;
                  const skipped = skippedMatch ? parseInt(skippedMatch[1]) : 0;
                  
                  totalTests += tests;
                  failedTests += failures;
                  errorTests += errors;
                  skippedTests += skipped;
                  passedTests += (tests - failures - errors - skipped);

                  // Extract test case details
                  const testCases = content.match(/<testcase[^>]*>[\s\S]*?<\/testcase>|<testcase[^>]*\/>/g) || [];
                  
                  testCases.forEach(testCase => {
                    const nameMatch = testCase.match(/name="([^"]+)"/);
                    const classnameMatch = testCase.match(/classname="([^"]+)"/);
                    
                    const testName = nameMatch ? nameMatch[1] : 'Unknown test';
                    const className = classnameMatch ? classnameMatch[1].split('.').pop() : '';
                    
                    if (testCase.includes('<failure')) {
                      const failureMatch = testCase.match(/<failure[^>]*>([\s\S]*?)<\/failure>/);
                      const message = failureMatch ? failureMatch[1].trim().split('\n')[0] : 'Test failed';
                      testDetails.push(`âŒ ${className}.${testName}\n   ${message}`);
                      failWorkflow = true;
                    } else if (testCase.includes('<error')) {
                      const errorMatch = testCase.match(/<error[^>]*>([\s\S]*?)<\/error>/);
                      const message = errorMatch ? errorMatch[1].trim().split('\n')[0] : 'Test error';
                      testDetails.push(`âŒ ${className}.${testName}\n   ${message}`);
                      failWorkflow = true;
                    } else if (testCase.includes('<skipped')) {
                      testDetails.push(`â­ï¸  ${className}.${testName}`);
                    } else {
                      testDetails.push(`âœ… ${className}.${testName}`);
                    }
                  });
                });

                const hasIssues = failedTests > 0 || errorTests > 0;
                const statusIcon = hasIssues ? 'âŒ' : 'âœ…';
                
                if (hasIssues) {
                  testOutput = '<details>\n' +
                    `<summary>Backend Unit Tests: (${passedTests} passed, ${failedTests} failures, ${errorTests} errors, ${skippedTests} skipped) ${statusIcon}</summary>\n\n` +
                    '```\n' +
                    testDetails.join('\n\n') + '\n' +
                    '```\n' +
                    '</details>';
                } else {
                  testOutput = '<details>\n' +
                    `<summary>Backend Unit Tests: (${passedTests} passed, 0 failures, 0 errors, ${skippedTests} skipped) ${statusIcon}</summary>\n\n` +
                    '```\n' +
                    testDetails.join('\n') + '\n' +
                    '```\n' +
                    '</details>';
                }
              } else {
                testOutput = 'Backend Unit Tests: âš ï¸ No test results found';
                failWorkflow = true;
              }
            } else {
              testOutput = 'Backend Unit Tests: âŒ Test execution failed';
              failWorkflow = true;
            }

            const commentBody = '## ğŸ” CI Tollgate Results\n\n' +
              testOutput + '\n';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });

            if (failWorkflow) {
              core.setFailed('CI tollgate failed: Test failures or errors detected.');
            }
